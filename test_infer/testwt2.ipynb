{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..', '/tmp', '/home/quanghung20gg/Documents/hung20gg/ielts_scoring/test_infer', '/home/quanghung20gg/anaconda3/lib/python311.zip', '/home/quanghung20gg/anaconda3/lib/python3.11', '/home/quanghung20gg/anaconda3/lib/python3.11/lib-dynload', '', '/home/quanghung20gg/anaconda3/lib/python3.11/site-packages', '/tmp/tmp2zu2ixn5']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login() # Get your token here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5e0c75fed4452da7034a1999ad66f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 23.67 GiB of which 70.00 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 65.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m\n\u001b[1;32m     16\u001b[0m change_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# pipeline = transformers.pipeline(\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     \"text-generation\",\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     model=model_id,\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     model_kwargs={\"torch_dtype\": torch.bfloat16},\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     device_map=\"auto\",\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     25\u001b[0m     model_id, \n\u001b[1;32m     26\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     27\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     28\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[1;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token_id\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    564\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    565\u001b[0m     )\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:3531\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3523\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3524\u001b[0m     (\n\u001b[1;32m   3525\u001b[0m         model,\n\u001b[1;32m   3526\u001b[0m         missing_keys,\n\u001b[1;32m   3527\u001b[0m         unexpected_keys,\n\u001b[1;32m   3528\u001b[0m         mismatched_keys,\n\u001b[1;32m   3529\u001b[0m         offload_index,\n\u001b[1;32m   3530\u001b[0m         error_msgs,\n\u001b[0;32m-> 3531\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_load_pretrained_model(\n\u001b[1;32m   3532\u001b[0m         model,\n\u001b[1;32m   3533\u001b[0m         state_dict,\n\u001b[1;32m   3534\u001b[0m         loaded_state_dict_keys,  \u001b[38;5;66;03m# XXX: rename?\u001b[39;00m\n\u001b[1;32m   3535\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3536\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3537\u001b[0m         ignore_mismatched_sizes\u001b[38;5;241m=\u001b[39mignore_mismatched_sizes,\n\u001b[1;32m   3538\u001b[0m         sharded_metadata\u001b[38;5;241m=\u001b[39msharded_metadata,\n\u001b[1;32m   3539\u001b[0m         _fast_init\u001b[38;5;241m=\u001b[39m_fast_init,\n\u001b[1;32m   3540\u001b[0m         low_cpu_mem_usage\u001b[38;5;241m=\u001b[39mlow_cpu_mem_usage,\n\u001b[1;32m   3541\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[1;32m   3542\u001b[0m         offload_folder\u001b[38;5;241m=\u001b[39moffload_folder,\n\u001b[1;32m   3543\u001b[0m         offload_state_dict\u001b[38;5;241m=\u001b[39moffload_state_dict,\n\u001b[1;32m   3544\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtorch_dtype,\n\u001b[1;32m   3545\u001b[0m         hf_quantizer\u001b[38;5;241m=\u001b[39mhf_quantizer,\n\u001b[1;32m   3546\u001b[0m         keep_in_fp32_modules\u001b[38;5;241m=\u001b[39mkeep_in_fp32_modules,\n\u001b[1;32m   3547\u001b[0m     )\n\u001b[1;32m   3549\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3550\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:3958\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3954\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   3955\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   3956\u001b[0m                 )\n\u001b[1;32m   3957\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3958\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m _load_state_dict_into_meta_model(\n\u001b[1;32m   3959\u001b[0m             model_to_load,\n\u001b[1;32m   3960\u001b[0m             state_dict,\n\u001b[1;32m   3961\u001b[0m             loaded_keys,\n\u001b[1;32m   3962\u001b[0m             start_prefix,\n\u001b[1;32m   3963\u001b[0m             expected_keys,\n\u001b[1;32m   3964\u001b[0m             device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[1;32m   3965\u001b[0m             offload_folder\u001b[38;5;241m=\u001b[39moffload_folder,\n\u001b[1;32m   3966\u001b[0m             offload_index\u001b[38;5;241m=\u001b[39moffload_index,\n\u001b[1;32m   3967\u001b[0m             state_dict_folder\u001b[38;5;241m=\u001b[39mstate_dict_folder,\n\u001b[1;32m   3968\u001b[0m             state_dict_index\u001b[38;5;241m=\u001b[39mstate_dict_index,\n\u001b[1;32m   3969\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   3970\u001b[0m             hf_quantizer\u001b[38;5;241m=\u001b[39mhf_quantizer,\n\u001b[1;32m   3971\u001b[0m             is_safetensors\u001b[38;5;241m=\u001b[39mis_safetensors,\n\u001b[1;32m   3972\u001b[0m             keep_in_fp32_modules\u001b[38;5;241m=\u001b[39mkeep_in_fp32_modules,\n\u001b[1;32m   3973\u001b[0m             unexpected_keys\u001b[38;5;241m=\u001b[39munexpected_keys,\n\u001b[1;32m   3974\u001b[0m         )\n\u001b[1;32m   3975\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   3976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:812\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[1;32m    801\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_quantized\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mrequires_parameters_quantization)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    810\u001b[0m ):\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 812\u001b[0m     set_module_tensor_to_device(model, param_name, param_device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mset_module_kwargs)\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    814\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/accelerate/utils/modeling.py:399\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    397\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 399\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 23.67 GiB of which 70.00 MiB is free. Including non-PyTorch memory, this process has 22.87 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 65.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from utils.extract import get_score, clean_output, get_essay\n",
    "from utils.prompt import rescore, indepth_feedback, until_correct, get_instruction_prompt, get_system_prompt\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"mistralai/Mistral-7B-v0.1\" # Super loose\n",
    "# model_id = 'google/gemma-7b-it'\n",
    "# model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "mode = 'easy'\n",
    "if 'llama' in model_id:\n",
    "    mode = 'harsh'\n",
    "    \n",
    "chatbot_role = 'system'\n",
    "change_mode = True\n",
    "# pipeline = transformers.pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_id,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    device_map=\"cuda\", \n",
    "    torch_dtype=\"auto\", \n",
    "    trust_remote_code=True, \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.generation_config.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES = 'cambridge/1x_3_7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cam 17**\n",
    "\n",
    "- Test 1: 6.5 7\n",
    "- Test 2: 6.5 6\n",
    "- Test 3: 6.5 7\n",
    "- Test 4: 6 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "with open('prompt/output_suggestion_format.txt', 'r') as f:\n",
    "    output_suggestion = f.read()\n",
    "    \n",
    "with open(f'sample/{EXAMPLES}/question.txt', 'r') as f:\n",
    "    essay_topic = f.read()\n",
    "\n",
    "with open(f'sample/{EXAMPLES}/answer.txt', 'r') as f:\n",
    "    student_response = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the System prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = get_system_prompt(False)\n",
    "instruction_prompt_1 = get_instruction_prompt(essay_topic, student_response)\n",
    "messages = [\n",
    "    # {\"role\": \"user\", \"content\": system_prompt},\n",
    "    # {\"role\": chatbot_role, \"content\": \"Sure\"},\n",
    "    {\"role\": chatbot_role, \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": instruction_prompt_1},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First generate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**General: 6.5**\n",
      "Overall Explanation: The essay presents a good discussion of the topic, but lacks depth and coherence in some areas. The writer has attempted to address both views, but the supporting evidence and examples are not consistently strong. The writing is clear, but the vocabulary and grammar could be more varied and accurate.\n",
      "\n",
      "**Task Response: 6**\n",
      "Explanation: The essay addresses the topic and presents both views, but the discussion is not as comprehensive as it could be. The writer has not fully explored the implications of each view and has not provided sufficient evidence to support their own opinion. The essay lacks a clear thesis statement and the writer has not effectively linked the different paragraphs together.\n",
      "\n",
      "**Coherence and Cohesion: 6**\n",
      "Explanation: The essay has a clear introduction and conclusion, but the body paragraphs could be more cohesive. The writer has used some transitional phrases, but the connections between paragraphs are not always smooth. The text could benefit from more explicit linking words and phrases to improve the flow of ideas.\n",
      "\n",
      "**Lexical Resource: 6**\n",
      "Explanation: The essay demonstrates a good range of vocabulary, but the writer has not always used the most accurate or precise words. There are some instances of overused or clichéd expressions, and the writer could benefit from using more nuanced and sophisticated vocabulary.\n",
      "\n",
      "**Grammatical Range and Accuracy: 6**\n",
      "Explanation: The essay demonstrates a good range of sentence structures, but there are some errors in grammar and punctuation. The writer has used some complex sentence structures, but there are instances of subject-verb agreement errors, incorrect use of the present perfect tense, and poor use of articles. The text could benefit from more attention to detail in terms of grammar and punctuation.\n",
      "\n",
      "Note: The overall score is calculated by taking the mean value of the four metric scores, rounded to 0.5. In this case, the overall score is 6.5.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "model_args = {\n",
    "    \"max_new_tokens\": 2000,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\":0.9,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "generation_args = {\n",
    "    \"model_args\": model_args,\n",
    "    \"role\": chatbot_role,\n",
    "}\n",
    "\n",
    "\n",
    "output1 = pipe(messages, **generation_args[\"model_args\"])\n",
    "output_1_text = output1[0][\"generated_text\"]\n",
    "messages.append({\"role\": \"assistant\", \"content\": output_1_text})\n",
    "print(output_1_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_role = 'assistant'\n",
    "generation_args = {\n",
    "    \"model_args\": model_args,\n",
    "    \"role\": chatbot_role,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are an English teaching assistant, and you are good at grading essays, and your students need you for their IELTS Academic essay task 2. You will be given the topic and student's response.\n",
      "    You should grade the essay general score and in 4 metrics in IELTS Writing, which are Task Response, Coherence and Cohesion, Lexical Resource and Grammatical Range and Accuracy. \n",
      "    The overall must be the mean value of 4 metric scores and can be a float value between 0 and 9 (round to .5), but each metric score should be an integer between 0 and 9.\n",
      "\n",
      "    The formula to calculate the general score is:\n",
      "    ```\n",
      "    ( ( Task_Response + Coherence_and_Cohesion + Lexical_Resource + Grammatical_Range_and_Accuracy) // 2 ) / 2 = General_score\n",
      "    ```\n",
      "\n",
      "\n",
      "    Recall the IELTS Writing band score criteria.\n",
      "\n",
      "    \n",
      "\n",
      "    In each metric, you should give a detailed explanation and point out exactly the student mistakes that led to that score.\n",
      "    Your output format should be like this:\n",
      "    **General: score**\n",
      "Overall Explanation:\n",
      "`Your detailed explanation`\n",
      "**metric_name : score**\n",
      "Explanation: \n",
      "`Your detailed explanation`\n",
      "\n",
      "For example:\n",
      "**General: 7**\n",
      "Overall Explanation: Your explanation\n",
      "**Task Response: 6**\n",
      "Explanation: Your explanation\n",
      "**Coherence and Cohesion: 7**\n",
      "Explanation: Your explanation\n",
      "**Lexical Resource: 8**\n",
      "Explanation: Your explanation\n",
      "**Grammatical Range and Accuracy: 7**\n",
      "Explanation: Your explanation\n",
      "\n",
      "    - The overall score should be the mean value of 4 metric scores, round down to .0 and .5, so make sure your evaluation right.\n",
      "    - Provide constructive feedback.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(messages[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_output  = until_correct(pipe, messages, **generation_args)\n",
    "general, tr, cc, lr, gr = get_score(adjust_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**General: 6.0**\n",
      "Overall Explanation: The essay presents a good discussion of the topic, but lacks depth and coherence in some areas. The writer has attempted to address both views, but the supporting evidence and examples are not consistently strong. The writing is clear, but the vocabulary and grammar could be more varied and accurate.\n",
      "\n",
      "**Task Response: 6**\n",
      "Explanation: The essay addresses the topic and presents both views, but the discussion is not as comprehensive as it could be. The writer has not fully explored the implications of each view and has not provided sufficient evidence to support their own opinion. The essay lacks a clear thesis statement and the writer has not effectively linked the different paragraphs together.\n",
      "\n",
      "**Coherence and Cohesion: 6**\n",
      "Explanation: The essay has a clear introduction and conclusion, but the body paragraphs could be more cohesive. The writer has used some transitional phrases, but the connections between paragraphs are not always smooth. The text could benefit from more explicit linking words and phrases to improve the flow of ideas.\n",
      "\n",
      "**Lexical Resource: 6**\n",
      "Explanation: The essay demonstrates a good range of vocabulary, but the writer has not always used the most accurate or precise words. There are some instances of overused or clichéd expressions, and the writer could benefit from using more nuanced and sophisticated vocabulary.\n",
      "\n",
      "**Grammatical Range and Accuracy: 6**\n",
      "Explanation: The essay demonstrates a good range of sentence structures, but there are some errors in grammar and punctuation. The writer has used some complex sentence structures, but there are instances of subject-verb agreement errors, incorrect use of the present perfect tense, and poor use of articles. The text could benefit from more attention to detail in terms of grammar and punctuation.\n",
      "\n",
      "Note: The overall score is calculated by taking the mean value of the four metric scores, rounded to 0.5. In this case, the overall score is 6.0.\n"
     ]
    }
   ],
   "source": [
    "print(clean_output(adjust_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    # {\"role\": \"user\", \"content\": system_prompt},\n",
    "    # {\"role\": chatbot_role, \"content\": \"Sure, I will be a scoring assistant for your IELTS writing task 2 essay.\"},\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": instruction_prompt_1},\n",
    "    {\"role\": generation_args[\"role\"], \"content\": clean_output(adjust_output)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for the mistake. You are correct that the scores I provided do not add up to a general score of 6.5. Here is the revised output:\n",
      "\n",
      "**General: 7.0**\n",
      "Overall Explanation: The essay presents a good discussion of the topic, with some strengths in addressing both views and providing examples. The writing is generally clear, coherent, and well-organized.\n",
      "\n",
      "**Task Response: 7**\n",
      "Explanation: The essay addresses the topic and presents both views, with some good supporting evidence and examples. The writer has attempted to address the implications of each view, and the discussion is generally well-structured.\n",
      "\n",
      "**Coherence and Cohesion: 7**\n",
      "Explanation: The essay has a clear introduction and conclusion, and the body paragraphs are generally well-organized. The writer has used some transitional phrases to link ideas together, and the text flows smoothly.\n",
      "\n",
      "**Lexical Resource: 7**\n",
      "Explanation: The essay demonstrates a good range of vocabulary, with some sophisticated and nuanced expressions. The writer has generally used accurate and precise words.\n",
      "\n",
      "**Grammatical Range and Accuracy: 7**\n",
      "Explanation: The essay demonstrates a good range of sentence structures, with some complex and varied sentences. The writer has generally used accurate and correct language.\n",
      "\n",
      "Note: The general score is now 7.0, which is the mean value of the four metric scores.\n"
     ]
    }
   ],
   "source": [
    "if change_mode:\n",
    "    rescore_output = rescore(pipe, messages, mode, **generation_args)\n",
    "    rescore_output = until_correct(pipe, messages, **generation_args)\n",
    "    general, tr, cc, lr, gr = get_score(rescore_output)\n",
    "    print(rescore_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide in-depth feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "first_output = clean_output(adjust_output)\n",
    "if change_mode:\n",
    "    first_output = clean_output(rescore_output)\n",
    "messages = [\n",
    "    {\"role\": generation_args[\"role\"], \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": instruction_prompt_1},\n",
    "    {\"role\": generation_args[\"role\"], \"content\": first_output},\n",
    "]\n",
    "rcm_output = indepth_feedback(pipe, messages, **generation_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**General: 6.5**\n",
      "Overall Explanation: The essay provides a good overview of the topic, discussing both sides of the argument and presenting a clear opinion. While the writing is clear, the vocabulary is limited, and there are some errors in grammar and punctuation. The essay could benefit from more depth and analysis, but it is generally well-structured and easy to follow.\n",
      "\n",
      "**Task Response: 7**\n",
      "Explanation: The essay addresses the topic adequately, presenting both sides of the argument and the writer's own opinion. However, the discussion is somewhat superficial, and the writer could benefit from providing more supporting details and examples to strengthen their argument. For instance, the writer mentions that advertisements can be successful in persuading people to buy things, but they do not provide any specific examples or statistics to support this claim. Additionally, the writer's own opinion is not fully developed, and they could benefit from providing more evidence and analysis to support their viewpoint.\n",
      "\n",
      "The writer also fails to fully address the opposing viewpoint, instead simply stating that some people think that advertisements are too prevalent to catch people's attention anymore. A more nuanced discussion of the opposing viewpoint, including potential counterarguments and refutations, would strengthen the essay.\n",
      "\n",
      "**Coherence and Cohesion: 7**\n",
      "Explanation: The essay is generally easy to follow, with a clear introduction, body, and conclusion. The writer uses transitional phrases to connect ideas, and the linking between paragraphs is mostly smooth. However, there are some instances of repetition, such as the repeated mention of the goal of advertisements to persuade people to buy things. Additionally, the writer could benefit from providing more connections between paragraphs, such as using more explicit transitions or summarizing the main points at the beginning of each paragraph.\n",
      "\n",
      "**Lexical Resource: 6**\n",
      "Explanation: The writer uses a moderate range of vocabulary, with some words being repeated throughout the essay. While the language is clear, it is not particularly sophisticated or nuanced. For instance, the writer uses the phrase \"seemingly hypnotize people\" to describe the effect of advertisements, but this phrase is not particularly precise or evocative. The writer could benefit from using more varied and precise vocabulary to describe their ideas.\n",
      "\n",
      "Additionally, the writer makes several errors in word choice, such as using the phrase \"after watching a dozen of advertisements\" instead of \"after watching a dozen advertisements\". This error is minor, but it detracts from the overall clarity and effectiveness of the essay.\n",
      "\n",
      "**Grammatical Range and Accuracy: 6**\n",
      "Explanation: The essay contains several errors in grammar and punctuation, such as missing articles, incorrect verb tenses, and incorrect use of commas. For instance, the writer writes \"The goal of advertisements is to get consumers to buy a targeted product, and while this method has been proven considerably successful generally, some people view it as too prevalent to catch the consumers' attention any more.\" This sentence is grammatically correct, but it could be improved by using more varied sentence structures and providing more precise language.\n",
      "\n",
      "The writer also uses the phrase \"the repeated sight of the scrumptious food may result in that person feeling hungry and succumbing to the advertisement at last\" which is grammatically incorrect and could be rephrased for better clarity.\n",
      "\n",
      "To improve this essay, the writer could benefit from:\n",
      "\n",
      "* Providing more depth and analysis of the topic, including specific examples and statistics to support their claims\n",
      "* Developing their own opinion more fully, including evidence and analysis to support their viewpoint\n",
      "* Addressing the opposing viewpoint more fully, including potential counterarguments and refutations\n",
      "* Using more varied and precise vocabulary to describe their ideas\n",
      "* Improving sentence structure and using more varied sentence forms\n",
      "* Correcting errors in grammar and punctuation\n"
     ]
    }
   ],
   "source": [
    "print(rcm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making adjustment to the essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TARGET = 7.5\n",
    "ADJUSTMENT_MODE = 'close_to_original'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "if ADJUSTMENT_MODE =='close_to_original' and change_mode:\n",
    "    general, tr, cc, lr, gr = get_score(adjust_output)\n",
    "    first_output = clean_output(adjust_output)\n",
    "    messages = [\n",
    "        {\"role\": generation_args[\"role\"], \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": instruction_prompt_1},\n",
    "        {\"role\": generation_args[\"role\"], \"content\": first_output},\n",
    "    ]\n",
    "    indepth_feedback(pipe, messages, **generation_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "CURRENT_TARGET = general\n",
    "\n",
    "if CURRENT_TARGET <= MAX_TARGET - 0.5:\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Making adjustment directly into the essay to improve at least 1 score in each metric. {output_suggestion}\"})\n",
    "    suggest_essay = pipe(messages, **generation_args[\"model_args\"])\n",
    "    \n",
    "else: \n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Making adjustment directly into the essay to optimize the essay. {output_suggestion}\"})\n",
    "    suggest_essay = pipe(messages, **generation_args[\"model_args\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Suggesting changes:**\n",
      "\n",
      "**Task Response:**\n",
      "\n",
      "* Provide more specific examples and evidence to support the claims made in the essay.\n",
      "\n",
      "**Coherence and Cohesion:**\n",
      "\n",
      "* Use transitional phrases to connect ideas between paragraphs, such as \"However,\" \"In addition,\" or \"Furthermore.\"\n",
      "* Use more varied sentence structures to make the writing more engaging.\n",
      "\n",
      "**Lexical Resource:**\n",
      "\n",
      "* Use more nuanced and varied vocabulary to describe the effects of advertisements, such as \"subconscious influence\" or \"mental persuasion.\"\n",
      "\n",
      "**Grammatical Range and Accuracy:**\n",
      "\n",
      "* Use more complex sentence structures, such as compound or complex sentences, to add variety to the writing.\n",
      "* Check for errors in grammar and punctuation, such as missing articles or incorrect verb tenses.\n",
      "\n",
      "**Revised Essay:**\n",
      "\n",
      "Advertisement has always been a crucial part of the world of marketing. Throughout the decades, we have seen a significant increase in the amount of advertisements, whether it is on the media like television or widespread through social network platforms. The goal of advertisements is to get consumers to buy a targeted product, and while this method has been proven considerably successful generally, some people view it as too prevalent to catch the consumers' attention any more.\n",
      "\n",
      "Advertisements can act as a strong persuasion device to seemingly hypnotize people into buying goods and services. This is so because of the tactics placed in the messages, such as showing people having a good time together when using a particular product, using bandwagon, showing only the upsides of usage, and applying compare and contrast strategies to show the effects of using the product and make it stand out. Even if people do not know it, these messages are repeated several times and soon it may brainwash people to finally go out and get the product. For instance, if a person is watching television and sees a certain advertisement of a snack many times, the repeated sight of the scrumptious food may result in that person feeling hungry and succumbing to the advertisement at last.\n",
      "\n",
      "However, there is another point of view in which the widespread of advertisements makes it a normal thing. After watching a dozen of advertisements, people will see it as a mere everyday routine and cease to pay attention to the message of the advertisement. Some people may even choose to turn off a television channel, for instance, only just to avoid seeing and hearing repetitive advertisements. After a certain frequency, they start to get bored and stop paying attention to ads. Hence, in the end, the main goal of advertisements is not complete since the people whom the messages are sent out to do not receive that message. A real-life example can be seen from advertisements in a particular social media platform, YouTube. In the YouTube marketing mechanism, advertisements are placed before and in between videos, hoping that the viewers would also be forced to watch the advertisements, too. However, this is not usually the case, since many people would just click \"Skip Ad\" and continue on.\n",
      "\n",
      "In conclusion, advertisements can be successful in persuading people to purchase goods and services, or they can be unsuccessful in many ways. They are very commonly seen nowadays, but not all of them fulfill their purpose. Thus, advertisements must be designed and presented in the correct way to result in the highest effectiveness.\n",
      "\n",
      "Note: I made minor adjustments to the essay to improve the scores, while maintaining the original meaning, wording, and phrase of the essay as much as possible.\n"
     ]
    }
   ],
   "source": [
    "print(suggest_essay[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Advertisement has always been a crucial part of the world of marketing. Throughout the decades, we have seen a significant increase in the amount of advertisements, whether it is on the media like television or widespread through social network platforms. The goal of advertisements is to get consumers to buy a targeted product, and while this method has been proven considerably successful generally, some people view it as too prevalent to catch the consumers' attention any more.\n",
      "\n",
      "Advertisements can act as a strong persuasion device to seemingly hypnotize people into buying goods and services. This is so because of the tactics placed in the messages, such as showing people having a good time together when using a particular product, using bandwagon, showing only the upsides of usage, and applying compare and contrast strategies to show the effects of using the product and make it stand out. Even if people do not know it, these messages are repeated several times and soon it may brainwash people to finally go out and get the product. For instance, if a person is watching television and sees a certain advertisement of a snack many times, the repeated sight of the scrumptious food may result in that person feeling hungry and succumbing to the advertisement at last.\n",
      "\n",
      "However, there is another point of view in which the widespread of advertisements makes it a normal thing. After watching a dozen of advertisements, people will see it as a mere everyday routine and cease to pay attention to the message of the advertisement. Some people may even choose to turn off a television channel, for instance, only just to avoid seeing and hearing repetitive advertisements. After a certain frequency, they start to get bored and stop paying attention to ads. Hence, in the end, the main goal of advertisements is not complete since the people whom the messages are sent out to do not receive that message. A real-life example can be seen from advertisements in a particular social media platform, YouTube. In the YouTube marketing mechanism, advertisements are placed before and in between videos, hoping that the viewers would also be forced to watch the advertisements, too. However, this is not usually the case, since many people would just click \"Skip Ad\" and continue on.\n",
      "\n",
      "In conclusion, advertisements can be successful in persuading people to purchase goods and services, or they can be unsuccessful in many ways. They are very commonly seen nowadays, but not all of them fulfill their purpose. Thus, advertisements must be designed and presented in the correct way to result in the highest effectiveness.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_essay(suggest_essay[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
